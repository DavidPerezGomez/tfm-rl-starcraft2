[DEFAULT]
map = Simple64
agent_key = multi.dqn.game_manager
model_id = multi_dqn_game_manager
experiment_path = %(models_path)s/best_32

visualize = true

reward_mode = score
score_method = get_game_score_delta

[train]
num_episodes = 40

fine_tune = true
use_random_subagents = false

time_displacement = 5

load_agent = false
load_networks_only = false

;dqn properties
dqn_size = medium
lr = 0.001
lr_milestones = 25
epsilon = 0.1190
epsilon_decay = 0.8945
min_epsilon = 0.002
batch_size = 512
gamma = 0.9985
main_network_update_frequency = 1
target_network_sync_frequency = 150
target_sync_mode = soft
update_tau = 0.1

;buffer properties
memory_size = 7500
burn_in = 1024

[train.subagent.base_manager]
model_path = %(models_path)s/best_32/multi_dqn_base_manager
load_agent = true
load_networks_only = true
buffer_file

reward_mode = score
score_method = get_base_efficiency_delta

lr = 0.0005
lr_milestones =
epsilon = 0.7
epsilon_decay = 0.895
min_epsilon = 0.002
batch_size = 512
gamma = 0.9985
main_network_update_frequency = 1
target_network_sync_frequency = 150
target_sync_mode = soft
update_tau = 0.1

;buffer properties
memory_size = 10000
;burn_in = 2100
burn_in = 1024

[train.subagent.army_recruit_manager]
model_path = %(models_path)s/best_32/multi_dqn_army_recruit_manager
load_agent = true
load_networks_only = true

reward_mode = score
score_method = get_army_spending_delta

lr = 0.0005
lr_milestones =
epsilon = 0.7
epsilon_decay = 0.895
min_epsilon = 0.002
batch_size = 512
gamma = 0.9985
main_network_update_frequency = 1
target_network_sync_frequency = 150
target_sync_mode = soft
update_tau = 0.1

;buffer properties
memory_size = 10000
;burn_in = 2100
burn_in = 1024

[train.subagent.army_attack_manager]
model_path = %(models_path)s/best_32/multi_dqn_army_attack_manager
;model_path = %(experiment_path)s/%(model_id)s/army_attack_manager
load_agent = true
load_networks_only = true

reward_mode = score
score_method = get_health_difference_score_delta

lr = 0.0005
lr_milestones =
epsilon = 0.7
epsilon_decay = 0.895
min_epsilon = 0.005
batch_size = 512
gamma = 0.9985
main_network_update_frequency = 1
target_network_sync_frequency = 150
target_sync_mode = soft
update_tau = 0.1

;buffer properties
memory_size = 10000
;burn_in = 2100
burn_in = 1024

[train.opponent]
agent_key = single.random
model_id = single_random

[exploit]
num_episodes = 100

use_random_subagents = false

load_agent = true
load_networks_only = false

[exploit.subagent.base_manager]
load_agent = true
load_networks_only = false

reward_mode = score
score_method = get_base_efficiency_delta

[exploit.subagent.army_recruit_manager]
load_agent = true
load_networks_only = false

reward_mode = score
score_method = get_army_spending_delta

[exploit.subagent.army_attack_manager]
load_agent = true
load_networks_only = false

reward_mode = score
score_method = get_health_difference_score_delta

[exploit.opponent]
agent_key = single.random
model_id = single_random